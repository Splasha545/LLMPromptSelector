{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PINECONE_API_KEY = \"cf10ee0c-8558-45e2-82b2-864bea80d179\"\n",
    "PINECONE_ENV = \"us-west4-gcp-free\"\n",
    "\n",
    "OPENAI_API_KEY = \"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\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexander\\Documents\\GPT_app\\Prompt_select_bot\\Prompt_Selector_Bot\\.venv\\Lib\\site-packages\\pinecone\\index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code is used to create vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(\"src/prompts_data_updated.csv\", csv_args={\n",
    "    'fieldnames': ['act', 'prompt']\n",
    "})\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
    "    environment=PINECONE_ENV  # next to api key in console\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name=\"promptsvectors\"\n",
    "\n",
    "docsearch = Pinecone.from_documents(documents, embeddings, index_name=index_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code is used to delete the vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.index.Index at 0x1f1392b5910>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pinecone.Index(\"promptsvectors\")\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.delete(deleteAll='true')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing retrieval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"act: Qualitative psychologist\\nprompt: Act as a qualitative psychologist. You are presented with a conversation transcript from an interview conducted with different user groups of a product called 'Digimaps'.\\\\nUsing thematic analysis which is defined here:\\\\n'SIX PHASES OF THEMATIC ANALYSIS\\\\nFamiliarization: Data analysis is facilitated by an in-depth knowledge of, and engagement with, the data set. Familiarization - reading and rereading transcripts, listening to audio-recordings, making notes of any initial analytic observations - helps the researcher to move the analysis beyond a focus on the most obvious meanings.\\\\nCoding: A systematic process of identifying and labelling relevant features of the data (in relation to the research question). Coding is the first step in the process of identifying patterns in the data because it groups together similar data segments.\\\\n'Searching' for themes: The 'search' for themes is not simply one of 'discovery; the themes are not in the data waiting to be uncovered by an intrepid researcher. Rather, the researcher clusters together codes to create a plausible mapping of key patterns in the data.\\\\nReviewing themes: The researcher pauses the process of theme generation to check whether the candidate themes exhibit a good 'fit' with the coded data and with the entire data set, and each has a clear, distinct 'essence' - or central organizing concept. Reviewing may lead to no or few changes, or to discarding the candidate themes and restarting the previous phase.\\\\nDefining and naming themes: Writing theme definitions (effectively a brief summary of each there/ and selecting a theme name ensure the conceptual clarity of each theme and provide a road map for the final write-up.\\\\nWriting the report: The researcher weaves together their analytic narrative and vivid, compeling data extracts. Themes provide the organizing framework for the analysis, but analytic concur sions are drawn across themes.'\\\\n\\\\nPerform qualitative thematic analysis on the presented conversation. Your goal is to 1) extract codes, 2) provide a list of quotes to each code, and 3) develop themes based on the extracted codes, to answer three research questions: 1) what are the user groups of EDINA Digimap, 2) what are their primary goals of using EDINA Digimap and, 3) are the features of Digimap positively or negatively contributing to their experience of achieving those goals?:\\\\nNote that you are given only one conversation with one user at a time. Thus, you should give an output that could then later be combined with another similar output, for a different conversation analysed by another model, to complete step 3).\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I want to perform thematic analysis\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_dictionary(input_string):\n",
    "    # Regular expression pattern to match dictionaries\n",
    "    pattern = r'\\{(?:[^{}]|(?0))*\\}'\n",
    "\n",
    "    # Search for the first dictionary in the input string\n",
    "    match = re.search(pattern, input_string)\n",
    "\n",
    "    if match:\n",
    "        # Extract the matched dictionary and convert it back to a Python dict object\n",
    "        extracted_dict_str = match.group(0)\n",
    "        extracted_dict = eval(extracted_dict_str)\n",
    "\n",
    "        return extracted_dict\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"No dictionary found in the input string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "input_string = \"\"\"Based on the provided prompt, the goal is to generate entertaining stories that are engaging, imaginative, and captivating. Therefore, we want to prioritize creativity and relevance while maintaining a reasonable level of factual accuracy. Here are the chosen settings and explanations:\n",
    "\n",
    "1. Temperature: A higher temperature encourages more creative and diverse outputs. Since the goal is to create engaging stories, we'll set the temperature to 0.8.\n",
    "\n",
    "2. Top-p: To balance creativity and relevance, we'll set top-p to 0.7. This value allows for interesting results without introducing too much randomness or errors.\n",
    "\n",
    "3. Presence Penalty: To avoid excessive repetition, we'll set the presence penalty to 0.5. This value helps to maintain diversity in the generated text.\n",
    "\n",
    "4. Frequency Penalty: We'll set the frequency penalty to 0.3. This value reduces the chance of generating repetitive phrases, while still allowing for some repetition when necessary to maintain coherence in the story.\n",
    "\n",
    "The chosen settings in dictionary format:\n",
    "\n",
    "{\n",
    "    \"temperature\": 0.8,\n",
    "    \"top_p\": 0.7,\n",
    "    \"presence_penalty\": 0.5,\n",
    "    \"frequency_penalty\": 0.3\n",
    "}\n",
    "\n",
    "And now I add some random {shiz klike} this {almost} { everywher {{ now }\n",
    "\"\"\"\n",
    "#extracted_dictionary = extract_dictionary(input_string)\n",
    "\n",
    "#print(\"Extracted Dictionary:\", extracted_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided prompt, the goal is to generate entertaining stories that are engaging, imaginative, and captivating. Therefore, we want to prioritize creativity and relevance while maintaining a reasonable level of factual accuracy. Here are the chosen settings and explanations:\n",
      "\n",
      "1. Temperature: A higher temperature encourages more creative and diverse outputs. Since the goal is to create engaging stories, we'll set the temperature to 0.8.\n",
      "\n",
      "2. Top-p: To balance creativity and relevance, we'll set top-p to 0.7. This value allows for interesting results without introducing too much randomness or errors.\n",
      "\n",
      "3. Presence Penalty: To avoid excessive repetition, we'll set the presence penalty to 0.5. This value helps to maintain diversity in the generated text.\n",
      "\n",
      "4. Frequency Penalty: We'll set the frequency penalty to 0.3. This value reduces the chance of generating repetitive phrases, while still allowing for some repetition when necessary to maintain coherence in the story.\n",
      "\n",
      "The chosen settings in dictionary format:\n",
      "\n",
      "\n",
      "{\n",
      "    \"temperature\": 0.8,\n",
      "    \"top_p\": 0.7,\n",
      "    \"presence_penalty\": 0.5,\n",
      "    \"frequency_penalty\": 0.3\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def find_nested_braces(text):\n",
    "    stack = []\n",
    "\n",
    "    for m in re.finditer(r'[{}]', text):\n",
    "        pos = m.start()\n",
    "\n",
    "        if m.group() == '{':\n",
    "            stack.append(pos)\n",
    "        elif stack:\n",
    "            start_pos = stack.pop()\n",
    "            if not stack:\n",
    "                explanation = text[:start_pos]\n",
    "                result = (text[start_pos:pos + 1])\n",
    "                break\n",
    "\n",
    "    return result, explanation\n",
    "\n",
    "pattern = r'\\{(?:[^{}]|(?R))*\\}'\n",
    "text = \"your_text_here\"\n",
    "matches, explanation = find_nested_braces(input_string)\n",
    "print(explanation)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}{}\n",
      "{{}}{{}}\n",
      "{{{}}}{{{}}}\n"
     ]
    }
   ],
   "source": [
    "#str = \"How {about} {{this}?\"#input_string\n",
    "str = \"{}{}\"\n",
    "#print(str)\n",
    "\n",
    "def escape(str):\n",
    "    stack = []\n",
    "    result = []\n",
    "    offset = 0\n",
    "\n",
    "    for m in re.finditer(r'[{}]', str):\n",
    "        pos = m.start()\n",
    "\n",
    "        if m.group() == '{':\n",
    "            stack.append(pos)\n",
    "        elif stack:\n",
    "            start_pos = stack.pop()\n",
    "            if not stack:\n",
    "                start_pos += offset\n",
    "                pos += offset\n",
    "                str = str[:start_pos] +'{'+ str[start_pos:pos + 1] + '}' + str[pos + 1:]\n",
    "                offset += 2\n",
    "    return str\n",
    "\n",
    "print(str)\n",
    "print(escape(str))\n",
    "print(escape(escape(str)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def check_escaped_braces(s):\n",
    "    i = 0\n",
    "    while i < len(s):\n",
    "        if s[i] == '{{':\n",
    "            if i+1 < len(s) and s[i+1] == '{':\n",
    "                # This is an escaped brace.\n",
    "                i += 2\n",
    "            else:\n",
    "                # This is an unescaped opening brace.\n",
    "                return False\n",
    "        elif s[i] == '}':\n",
    "            if i+1 < len(s) and s[i+1] == '}}':\n",
    "                # This is an escaped brace.\n",
    "                i += 2\n",
    "            else:\n",
    "               # This is an unescaped closing brace.\n",
    "               return False \n",
    "        else:\n",
    "           # It's some other character; ignore it.\n",
    "           i += 1\n",
    "\n",
    "    return True   # If we've gone through every character without returning False, then all braces were properly escaped.\n",
    "\n",
    "# Test cases:\n",
    "print(check_escaped_braces(\"{{Hello}}\"))       # False - Unescaped braces found!\n",
    "print(check_escaped_braces(\"{{{Hello}}}\"))     # True - All braces are properly escaped!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like {{dogs}}\n",
      "{{cats}} or {{dogs}}\n",
      "So, lets {{say}} I have {some{thing}} like this {{then}}. Then a dictionary: {{lol: 'kek'}}. Then some random brackets {{}}\n"
     ]
    }
   ],
   "source": [
    "def escape_brackets(s):\n",
    "    # First, we detect all singly enclosed curly brackets\n",
    "    # that are not already escaped.\n",
    "    matches = re.findall(r\"(?<!\\{)\\{[^{}]*\\}(?!\\})\", s)\n",
    "\n",
    "    # For each match, we replace it in the string with its escaped version.\n",
    "    for match in matches:\n",
    "        s = s.replace(match, \"{{\" + match[1:-1] + \"}}\")\n",
    "\n",
    "    return s\n",
    "\n",
    "print(escape_brackets(\"I like {dogs}\"))  # Outputs: \"I like {{dogs}}\"\n",
    "print(escape_brackets(\"{{cats}} or {dogs}\"))  # Outputs: \"{{cats}} or {{dogs}}\"\n",
    "\n",
    "print(escape_brackets(\"So, lets {say} I have {some{thing}} like this {then}. Then a dictionary: {lol: 'kek'}. Then some random brackets {{}}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How {{{{about}}}} {{{{this}}?\n",
      "How {{about}} {{{{this}}?\n"
     ]
    }
   ],
   "source": [
    "def escape(input_string):\n",
    "    input_string = input_string.replace(\"{\", \"{{\")\n",
    "    input_string = input_string.replace(\"}\", \"}}\")\n",
    "    \n",
    "    print(input_string)\n",
    "    \n",
    "escape(\"How {{about}} {{this}?\")\n",
    "\n",
    "print(\"How {{about} this}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pypdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[121], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpypdf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pypdf'"
     ]
    }
   ],
   "source": [
    "import pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def load_saved_conversation(chat_name):\n",
    "    \n",
    "    st_interactions = []\n",
    "    # Get saved chat interactions:\n",
    "    folder_path = \"conversations\"\n",
    "    filename = f\"{chat_name}_prompt.txt\"\n",
    "    with open(os.path.join(folder_path, filename), \"r\") as file:\n",
    "        content = file.read()\n",
    "        chat = content.split(\"CHAT:\")[1]\n",
    "        print(chat)\n",
    "        for message in chat.split(\"CHAT MESSAGE: \"):\n",
    "            try:\n",
    "                message_dict = eval(message)\n",
    "                st_interactions.append(message_dict)\n",
    "            except SyntaxError:\n",
    "                # Handle invalid settings format\n",
    "                print(f\"Message not saved in valid format! Message: {message}\")\n",
    "    return st_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAT MESSAGE: {'role': 'system', 'content': 'Hello! How can I assist you today?'}CHAT MESSAGE: {'role': 'user', 'content': 'Im going to send you a string'}CHAT MESSAGE: {'role': 'system', 'content': 'Sure, go ahead and send me the string.'}CHAT MESSAGE: {'role': 'user', 'content': '\"User: Python  \\nSystem: Are you referring to the Python programming language? \\n\\nUser: I have files which contain information like so:\\n\"PROMPT: [some prompt text]\\nSETTINGS: [settings in curly brackets written like a dictionary]\\nMODEL: [name of model text]\"\\n\\nHow would I extract each of the into separate variables, such that the settings variable is a dictionary and the model and prompt variables are strings?\\n\\nSystem: To extract the information from each file and store them in separate variables, you can use the following steps:\\n\\n1. Import the `os` module to work with files.\\n2. Create an empty list to store the extracted data.\\n3. Use `os.listdir()` to get a list of files in a specified folder.\\n4. Iterate over each file in the list.\\n5. Open each file using `open()` and read its contents using `.read()`.\\n6. Extract the prompt, settings, and model information from each file by splitting the content based on specific patterns or delimiters.\\n7. Store the prompt as a string variable, settings as a dictionary variable (you may need to parse it if it\\'s not already in JSON format), and model as a string variable.\\n8. Append these variables into a dictionary with keys \\'Prompt\\', \\'Settings\\', and \\'Model\\'.\\n9. Append this dictionary to your result_list.\\n\\nHere is an example code snippet that demonstrates these steps:\\n\\n```python\\nimport os\\n\\nresult_list = []\\n\\nfolder_path = \"path/to/your/folder\"\\n\\nfor filename in os.listdir(folder_path):\\n    if filename.endswith(\".txt\"):\\n        with open(os.path.join(folder_path, filename), \"r\") as file:\\n            content = file.read()\\n            \\n            # Extracting prompt\\n            prompt_start_index = content.find(\"PROMPT: \") + len(\"PROMPT: \")\\n            prompt_end_index = content.find(\"\\\\n\", prompt_start_index)\\n            prompt = content[prompt_start_index:prompt_end_index]\\n            \\n            # Extracting settings\\n            settings_start_index = content.find(\"SETTINGS: \") + len(\"SETTINGS: \")\\n            settings_end_index = content.find(\"\\\\n\", settings_start_index)\\n            settings_str = content[settings_start_index:settings_end_index]\\n            \\n            # Parsing settings into dictionary\\n            try:\\n                settings_dict = eval(settings_str)  # Assuming settings are in valid dictionary format\\n            except SyntaxError:\\n                # Handle invalid settings format\\n                continue\\n            \\n            # Extracting model\\n            model_start_index = content.find(\"MODEL: \") + len(\"MODEL: \")\\n            model_end_index = content.find(\"\\\\n\", model_start_index)\\n            model = content[model_start_index:model_end_index]\\n            \\n            result_dict = {{\\n                \\'Prompt\\': prompt,\\n                \\'Settings\\': settings_dict,\\n                \\'Model\\': model\\n            }}\\n            \\n            result_list.append(result_dict)\\n```\\n\\nThis code will iterate over all .txt files in the specified folder, extract the prompt, settings, and model information from each file, and store them in a list of dictionaries called `result_list`.\\n\\nUser: Now imagine I have a string that looks like this:\\n\"User: Building  \\nSystem: What kind of assistance are you looking for in building? \\n\\nUser: Arrange flowers for an office building\\nSystem: Sure, I can help you with that. When it comes to arranging flowers for an office building, it\\'s important to consider the overall aesthetic and the preferences of the people working there. Could you please provide more details about your specific requirements and preferences?\\n\\nUser: Middle of the city, modern office building\\nSystem: For a modern office building located in the middle of the city, you can consider incorporating sleek and contemporary floral arrangements. Here are some suggestions:\\n\\n1. Minimalistic Centerpieces: Opt for simple yet elegant centerpieces using flowers like orchids or calla lilies. Arrange them in clear glass vases with clean lines to complement the modern aesthetic.\\n\\n2. Vertical Flower Walls: Create a striking visual impact by installing vertical flower walls in the lobby or common areas. Choose flowers like roses or hydrangeas in various shades to add depth and dimension.\\n\\n3. Potted Plants: Incorporate potted plants with interesting foliage, such as snake plants or peace lilies, to bring a touch of greenery indoors. These low-maintenance plants will thrive in an office environment.\\n\\n4. Scented Flowers: To add pleasing fragrances, consider including scented flowers like lavender or jasmine in your arrangements. Their subtle scents can create a calming atmosphere for employees and visitors.\\n\\n5. Long-lasting Blooms: Select flowers that have a longer lifespan, such as carnations or alstroemerias, to ensure that the arrangements stay intact for a longer duration without wilting quickly.\\n\\nRemember to consult with professional florists who have experience in creating modern floral designs to ensure customer satisfaction and achieve the desired aesthetic appeal for your office building.\\n\\nUser: Ok\\nSystem: Thank you for your response. If you have any specific questions or need further assistance, feel free to ask!\"\"'}CHAT MESSAGE: {'role': 'system', 'content': 'Thank you for your response. If you have any specific questions or need further assistance, feel free to ask!'}CHAT MESSAGE: {'role': 'user', 'content': 'What do you make of the string'}CHAT MESSAGE: {'role': 'system', 'content': \"The string you provided appears to be a conversation between a user and a system. It contains information about the user's request to arrange flowers for an office building and the system's response with suggestions and recommendations.\"}\n",
      "Message not saved in valid format! Message: \n",
      "[{'role': 'system', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Im going to send you a string'}, {'role': 'system', 'content': 'Sure, go ahead and send me the string.'}, {'role': 'user', 'content': '\"User: Python  \\nSystem: Are you referring to the Python programming language? \\n\\nUser: I have files which contain information like so:\\n\"PROMPT: [some prompt text]\\nSETTINGS: [settings in curly brackets written like a dictionary]\\nMODEL: [name of model text]\"\\n\\nHow would I extract each of the into separate variables, such that the settings variable is a dictionary and the model and prompt variables are strings?\\n\\nSystem: To extract the information from each file and store them in separate variables, you can use the following steps:\\n\\n1. Import the `os` module to work with files.\\n2. Create an empty list to store the extracted data.\\n3. Use `os.listdir()` to get a list of files in a specified folder.\\n4. Iterate over each file in the list.\\n5. Open each file using `open()` and read its contents using `.read()`.\\n6. Extract the prompt, settings, and model information from each file by splitting the content based on specific patterns or delimiters.\\n7. Store the prompt as a string variable, settings as a dictionary variable (you may need to parse it if it\\'s not already in JSON format), and model as a string variable.\\n8. Append these variables into a dictionary with keys \\'Prompt\\', \\'Settings\\', and \\'Model\\'.\\n9. Append this dictionary to your result_list.\\n\\nHere is an example code snippet that demonstrates these steps:\\n\\n```python\\nimport os\\n\\nresult_list = []\\n\\nfolder_path = \"path/to/your/folder\"\\n\\nfor filename in os.listdir(folder_path):\\n    if filename.endswith(\".txt\"):\\n        with open(os.path.join(folder_path, filename), \"r\") as file:\\n            content = file.read()\\n            \\n            # Extracting prompt\\n            prompt_start_index = content.find(\"PROMPT: \") + len(\"PROMPT: \")\\n            prompt_end_index = content.find(\"\\\\n\", prompt_start_index)\\n            prompt = content[prompt_start_index:prompt_end_index]\\n            \\n            # Extracting settings\\n            settings_start_index = content.find(\"SETTINGS: \") + len(\"SETTINGS: \")\\n            settings_end_index = content.find(\"\\\\n\", settings_start_index)\\n            settings_str = content[settings_start_index:settings_end_index]\\n            \\n            # Parsing settings into dictionary\\n            try:\\n                settings_dict = eval(settings_str)  # Assuming settings are in valid dictionary format\\n            except SyntaxError:\\n                # Handle invalid settings format\\n                continue\\n            \\n            # Extracting model\\n            model_start_index = content.find(\"MODEL: \") + len(\"MODEL: \")\\n            model_end_index = content.find(\"\\\\n\", model_start_index)\\n            model = content[model_start_index:model_end_index]\\n            \\n            result_dict = {{\\n                \\'Prompt\\': prompt,\\n                \\'Settings\\': settings_dict,\\n                \\'Model\\': model\\n            }}\\n            \\n            result_list.append(result_dict)\\n```\\n\\nThis code will iterate over all .txt files in the specified folder, extract the prompt, settings, and model information from each file, and store them in a list of dictionaries called `result_list`.\\n\\nUser: Now imagine I have a string that looks like this:\\n\"User: Building  \\nSystem: What kind of assistance are you looking for in building? \\n\\nUser: Arrange flowers for an office building\\nSystem: Sure, I can help you with that. When it comes to arranging flowers for an office building, it\\'s important to consider the overall aesthetic and the preferences of the people working there. Could you please provide more details about your specific requirements and preferences?\\n\\nUser: Middle of the city, modern office building\\nSystem: For a modern office building located in the middle of the city, you can consider incorporating sleek and contemporary floral arrangements. Here are some suggestions:\\n\\n1. Minimalistic Centerpieces: Opt for simple yet elegant centerpieces using flowers like orchids or calla lilies. Arrange them in clear glass vases with clean lines to complement the modern aesthetic.\\n\\n2. Vertical Flower Walls: Create a striking visual impact by installing vertical flower walls in the lobby or common areas. Choose flowers like roses or hydrangeas in various shades to add depth and dimension.\\n\\n3. Potted Plants: Incorporate potted plants with interesting foliage, such as snake plants or peace lilies, to bring a touch of greenery indoors. These low-maintenance plants will thrive in an office environment.\\n\\n4. Scented Flowers: To add pleasing fragrances, consider including scented flowers like lavender or jasmine in your arrangements. Their subtle scents can create a calming atmosphere for employees and visitors.\\n\\n5. Long-lasting Blooms: Select flowers that have a longer lifespan, such as carnations or alstroemerias, to ensure that the arrangements stay intact for a longer duration without wilting quickly.\\n\\nRemember to consult with professional florists who have experience in creating modern floral designs to ensure customer satisfaction and achieve the desired aesthetic appeal for your office building.\\n\\nUser: Ok\\nSystem: Thank you for your response. If you have any specific questions or need further assistance, feel free to ask!\"\"'}, {'role': 'system', 'content': 'Thank you for your response. If you have any specific questions or need further assistance, feel free to ask!'}, {'role': 'user', 'content': 'What do you make of the string'}, {'role': 'system', 'content': \"The string you provided appears to be a conversation between a user and a system. It contains information about the user's request to arrange flowers for an office building and the system's response with suggestions and recommendations.\"}]\n"
     ]
    }
   ],
   "source": [
    "chat_interactions = load_saved_conversation(\"test\")\n",
    "print(chat_interactions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
